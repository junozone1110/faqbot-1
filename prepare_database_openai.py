#!/usr/bin/env python3
"""
PDFèª­ã¿è¾¼ã¿ã¨ãƒ™ã‚¯ãƒˆãƒ«DBä¿å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (OpenAI Embeddingsç‰ˆ)
Google Driveã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒãƒ£ãƒ³ã‚¯åŒ–ã—ã¦ChromaDBã«ä¿å­˜ã—ã¾ã™ã€‚
OpenAIã®é«˜ç²¾åº¦ãªåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
"""

import os
import shutil
from pathlib import Path
from typing import List

from dotenv import load_dotenv
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import fitz  # PyMuPDF

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# è¨­å®š
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']
TEMP_PDF_DIR = Path("./temp_pdf")
CHROMA_DB_DIR = "./chroma_db_openai"

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
GOOGLE_DRIVE_FOLDER_ID = os.getenv("GOOGLE_DRIVE_FOLDER_ID")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def authenticate_google_drive():
    """Google Drive APIã®èªè¨¼ã‚’è¡Œã„ã¾ã™"""
    creds = None
    
    # token.jsonãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚€
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    
    # èªè¨¼æƒ…å ±ãŒãªã„ã€ã¾ãŸã¯ç„¡åŠ¹ãªå ´åˆ
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        
        # èªè¨¼æƒ…å ±ã‚’ä¿å­˜
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
    
    return build('drive', 'v3', credentials=creds)


def get_all_pdfs_recursive(service, folder_id: str, path_prefix: str = ""):
    """æŒ‡å®šã—ãŸGoogle Driveãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å†å¸°çš„ã«ã™ã¹ã¦ã®PDFã‚’å–å¾—ã—ã¾ã™"""
    all_pdfs = []
    
    # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
    query = f"'{folder_id}' in parents and trashed=false"
    results = service.files().list(
        q=query,
        fields="files(id, name, mimeType)"
    ).execute()
    
    items = results.get('files', [])
    
    for item in items:
        item_name = item['name']
        item_id = item['id']
        mime_type = item['mimeType']
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        if mime_type == 'application/pdf':
            full_path = f"{path_prefix}/{item_name}" if path_prefix else item_name
            all_pdfs.append({
                'id': item_id,
                'name': item_name,
                'path': full_path
            })
        
        # ãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆã€å†å¸°çš„ã«æ¢ç´¢
        elif mime_type == 'application/vnd.google-apps.folder':
            folder_path = f"{path_prefix}/{item_name}" if path_prefix else item_name
            print(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ç´¢ä¸­: {folder_path}")
            sub_pdfs = get_all_pdfs_recursive(service, item_id, folder_path)
            all_pdfs.extend(sub_pdfs)
    
    return all_pdfs


def download_pdfs_from_drive(service, folder_id: str, download_dir: Path):
    """æŒ‡å®šã—ãŸGoogle Driveãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã™ã¹ã¦ã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆå†å¸°çš„ï¼‰"""
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    download_dir.mkdir(exist_ok=True)
    
    # å†å¸°çš„ã«PDFã‚’å–å¾—
    print("ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’æ¢ç´¢ä¸­...")
    pdf_files = get_all_pdfs_recursive(service, folder_id)
    
    if not pdf_files:
        print("PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return []
    
    print(f"\nåˆè¨ˆ{len(pdf_files)}å€‹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
    
    downloaded_files = []
    for pdf_info in pdf_files:
        file_id = pdf_info['id']
        file_name = pdf_info['name']
        full_path_in_drive = pdf_info['path']
        local_file_path = download_dir / file_name
        
        print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {full_path_in_drive}")
        
        request = service.files().get_media(fileId=file_id)
        with open(local_file_path, 'wb') as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
                if status:
                    print(f"  é€²æ—: {int(status.progress() * 100)}%")
        
        downloaded_files.append(local_file_path)
    
    return downloaded_files


def extract_text_from_pdf(pdf_path: Path) -> str:
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã™"""
    print(f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­: {pdf_path.name}")
    
    doc = fitz.open(pdf_path)
    text = ""
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        text += page.get_text()
    
    doc.close()
    return text


def create_chunks(texts: List[dict], chunk_size: int = 1500, chunk_overlap: int = 300) -> List[dict]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã™"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
    )
    
    all_chunks = []
    
    for text_dict in texts:
        chunks = text_splitter.split_text(text_dict['text'])
        for i, chunk in enumerate(chunks):
            all_chunks.append({
                'text': chunk,
                'source': text_dict['source'],
                'chunk_id': f"{text_dict['source']}_chunk_{i}"
            })
    
    return all_chunks


def save_to_chroma(chunks: List[dict], embedding_model):
    """ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ChromaDBã«ä¿å­˜ã—ã¾ã™ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰"""
    total_chunks = len(chunks)
    print(f"\nä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {embedding_model.model} (é«˜ç²¾åº¦)")
    
    # æ—¢å­˜ã®DBãŒã‚ã‚Œã°å‰Šé™¤
    if os.path.exists(CHROMA_DB_DIR):
        shutil.rmtree(CHROMA_DB_DIR)
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆOpenAIã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«å¯¾å¿œï¼‰
    BATCH_SIZE = 100  # 100ãƒãƒ£ãƒ³ã‚¯ãšã¤å‡¦ç†
    
    print(f"\n{total_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’{BATCH_SIZE}å€‹ãšã¤ãƒãƒƒãƒå‡¦ç†ã§ä¿å­˜ä¸­...")
    
    vectordb = None
    for i in range(0, total_chunks, BATCH_SIZE):
        batch = chunks[i:i+BATCH_SIZE]
        batch_texts = [chunk['text'] for chunk in batch]
        batch_metadatas = [{'source': chunk['source'], 'chunk_id': chunk['chunk_id']} for chunk in batch]
        
        batch_num = (i // BATCH_SIZE) + 1
        total_batches = (total_chunks + BATCH_SIZE - 1) // BATCH_SIZE
        print(f"  ãƒãƒƒãƒ {batch_num}/{total_batches} ({len(batch)}ãƒãƒ£ãƒ³ã‚¯) ã‚’å‡¦ç†ä¸­...")
        
        if vectordb is None:
            # æœ€åˆã®ãƒãƒƒãƒã§DBã‚’ä½œæˆ
            vectordb = Chroma.from_texts(
                texts=batch_texts,
                embedding=embedding_model,
                metadatas=batch_metadatas,
                persist_directory=CHROMA_DB_DIR
            )
        else:
            # 2å›ç›®ä»¥é™ã¯æ—¢å­˜ã®DBã«è¿½åŠ 
            vectordb.add_texts(
                texts=batch_texts,
                metadatas=batch_metadatas
            )
    
    print(f"\nâœ“ ãƒ™ã‚¯ãƒˆãƒ«DBã®ä¿å­˜å®Œäº†: {CHROMA_DB_DIR}")
    print(f"  åˆè¨ˆãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}")
    return vectordb


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== FAQãƒœãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (OpenAI Embeddingsç‰ˆ) ===\n")
    
    # ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    if not GOOGLE_DRIVE_FOLDER_ID or not OPENAI_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: .envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_DRIVE_FOLDER_IDã¨OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        print("\nOpenAI APIã‚­ãƒ¼ã®å–å¾—æ–¹æ³•:")
        print("1. https://platform.openai.com/api-keys ã«ã‚¢ã‚¯ã‚»ã‚¹")
        print("2. 'Create new secret key' ã‚’ã‚¯ãƒªãƒƒã‚¯")
        print("3. ç”Ÿæˆã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’.envãƒ•ã‚¡ã‚¤ãƒ«ã®OPENAI_API_KEYã«è¨­å®š")
        return
    
    # Step 1: Google Driveèªè¨¼
    print("Step 1: Google Driveã«æ¥ç¶šä¸­...")
    service = authenticate_google_drive()
    print("èªè¨¼å®Œäº†\n")
    
    # Step 2: PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    print("Step 2: PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    pdf_files = download_pdfs_from_drive(service, GOOGLE_DRIVE_FOLDER_ID, TEMP_PDF_DIR)
    print(f"{len(pdf_files)}å€‹ã®PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\n")
    
    if not pdf_files:
        print("PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return
    
    # Step 3: ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    print("Step 3: PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­...")
    texts = []
    for pdf_path in pdf_files:
        text = extract_text_from_pdf(pdf_path)
        texts.append({
            'text': text,
            'source': pdf_path.name
        })
    print("ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†\n")
    
    # Step 4: ãƒãƒ£ãƒ³ã‚¯åŒ–
    print("Step 4: ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ä¸­...")
    chunks = create_chunks(texts)
    print(f"{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ\n")
    
    # Step 5: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ChromaDBã¸ã®ä¿å­˜
    print("Step 5: OpenAI Embeddingsã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ChromaDBã«ä¿å­˜ä¸­...")
    print("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: text-embedding-3-large (é«˜ç²¾åº¦)")
    embedding_model = OpenAIEmbeddings(
        model="text-embedding-3-large",
        openai_api_key=OPENAI_API_KEY
    )
    save_to_chroma(chunks, embedding_model)
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("\nä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    if TEMP_PDF_DIR.exists():
        shutil.rmtree(TEMP_PDF_DIR)
    
    print("\n=== å‡¦ç†å®Œäº† ===")
    print("OpenAI Embeddingsã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«DBã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    print("æ¬¡ã¯ ask_bot_openai.py ã‚’å®Ÿè¡Œã—ã¦è³ªå•ã«å›ç­”ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")


if __name__ == "__main__":
    main()

