#!/usr/bin/env python3
"""
FAQ Bot for Slack with Hybrid Search
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸSlack Bot
"""

import os
import re
import json
from dotenv import load_dotenv
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler

from langchain_openai import OpenAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

from hybrid_search import HybridSearchRetriever

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Slackè¨­å®š
SLACK_BOT_TOKEN = os.getenv("SLACK_BOT_TOKEN")
SLACK_APP_TOKEN = os.getenv("SLACK_APP_TOKEN")

# FAQ Botè¨­å®š
CHROMA_DB_DIR = "./chroma_db_openai"
TOP_K_RESULTS = 5  # æ¤œç´¢çµæœã®ä¸Šä½ä»¶æ•°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ï¼ˆè¿½åŠ è³ªå•ã®å±¥æ­´ã‚’ä¿æŒï¼‰
thread_contexts = {}

# æ³•å¾‹ã®ç¨®é¡ãƒãƒƒãƒ”ãƒ³ã‚°
LAW_TYPES = {
    "keihyouhou": "æ™¯è¡¨æ³•",
    "shikin_kessai": "è³‡é‡‘æ±ºæ¸ˆæ³•",
    "kojin_jouhou": "å€‹äººæƒ…å ±ä¿è­·æ³•",
    "inshi_zei": "å°ç´™ç¨æ³•"
}

# æ³•å¾‹ã¨ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ï¼‰
LAW_SOURCE_MAPPING = {
    "æ™¯è¡¨æ³•": [
        "ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•.pdf",
        "ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•æ–½è¡Œè¦å‰‡.pdf",
        "æ™¯å“ã«é–¢ã™ã‚‹Q&A.pdf"
    ],
    "è³‡é‡‘æ±ºæ¸ˆæ³•": [
        "è³‡é‡‘æ±ºæ¸ˆã«é–¢ã™ã‚‹æ³•å¾‹.pdf",
        "è³‡é‡‘æ±ºæ¸ˆã«é–¢ã™ã‚‹æ³•å¾‹æ–½è¡Œä»¤.pdf",
        "å‰æ‰•å¼æ”¯æ‰•æ‰‹æ®µã«ã¤ã„ã¦ã‚ˆãã‚ã‚‹ã”è³ªå•231027.pdf"
    ],
    "å€‹äººæƒ…å ±ä¿è­·æ³•": [
        "å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹.pdf",
        "å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹æ–½è¡Œè¦å‰‡.pdf",
        "å€‹äººæƒ…å ±ä¿è­·å§”å“¡ä¼šã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³é€šå‰‡ç·¨.pdf",
        "å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹ã«ã¤ã„ã¦ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³.pdf",
        "å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹ã«ã¤ã„ã¦ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ ï¼ˆä»®ååŠ å·¥æƒ…å ±ãƒ»åŒ¿ååŠ å·¥æƒ…å ±ç·¨ï¼‰.pdf",
        "å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹ã«ã¤ã„ã¦ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ ï¼ˆç¬¬ä¸‰è€…æä¾›æ™‚ã®ç¢ºèªãƒ»è¨˜éŒ²ç¾©å‹™ç·¨ï¼‰.pdf",
        "ã€Œå€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹ã«ã¤ã„ã¦ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ ã«é–¢ã™ã‚‹ï¼±ï¼†ï¼¡.pdf"
    ],
    "å°ç´™ç¨æ³•": [
        "å°ç´™ç¨æ³•.pdf",
        "å°ç´™ä¸€è¦§.pdf"
    ]
}

# è³ªå•ã®æ›–æ˜§ã•ãƒã‚§ãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
CLARITY_CHECK_PROMPT = """
ã‚ãªãŸã¯æ³•å¾‹ç›¸è«‡ã«ãŠã‘ã‚‹è³ªå•ã®å…·ä½“æ€§ã‚’è©•ä¾¡ã™ã‚‹å³æ ¼ãªå°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®è³ªå•ãŒã€Œ{law_type}ã€ã«é–¢ã™ã‚‹æ³•å¾‹ç›¸è«‡ã¨ã—ã¦ååˆ†ã«å…·ä½“çš„ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

**é‡è¦ãªå‰æ**:
æ³•å¾‹ã®é©ç”¨åˆ¤æ–­ã‚„æ³•çš„è©•ä¾¡ã‚’æ±‚ã‚ã‚‹è³ªå•ã®å ´åˆã€ä»¥ä¸‹ã®å…·ä½“çš„æƒ…å ±ãŒã»ã¼å¿…é ˆã§ã™ï¼š
- é‡‘é¡ãƒ»è¦æ¨¡ï¼ˆæ•°å€¤ï¼‰
- å…·ä½“çš„ãªä¸»ä½“ï¼ˆèª°ãŒã€ã©ã®ã‚ˆã†ãªç«‹å ´ã§ï¼‰
- å…·ä½“çš„ãªçŠ¶æ³ãƒ»è¡Œç‚ºã®å†…å®¹
- æ™‚æœŸãƒ»æœŸé–“ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

**è©•ä¾¡åŸºæº–**:
è³ªå•ã«ã¯ä»¥ä¸‹ã®è¦³ç‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¹ãã§ã™ï¼š

1. **Whatï¼ˆä½•ã‚’ï¼‰** - å¿…é ˆ
   - å…·ä½“çš„ãªãƒˆãƒ”ãƒƒã‚¯ã€ç”¨èªã€åˆ¶åº¦ã€è¡Œç‚ºãŒæ˜ç¢ºã‹
   - å˜ãªã‚‹ä¸€èˆ¬åè©ã§ã¯ãªãã€å…·ä½“çš„ãªå†…å®¹ãŒç‰¹å®šã§ãã‚‹ã‹

2. **Whoï¼ˆèª°ãŒï¼‰** - æ³•å¾‹é©ç”¨åˆ¤æ–­ã«ã¯å¿…é ˆ
   - ä¸»ä½“ã®ç«‹å ´ï¼ˆäº‹æ¥­è€…/æ¶ˆè²»è€…/å€‹äºº/æ³•äººï¼‰
   - äº‹æ¥­å½¢æ…‹ã€è¦æ¨¡ãªã©

3. **How muchï¼ˆã„ãã‚‰ï¼‰** - é‡‘é¡åŸºæº–ãŒã‚ã‚‹æ³•å¾‹ã§ã¯å¿…é ˆ
   - é‡‘é¡ã€è¦æ¨¡ã€æ•°é‡ãªã©ã®å…·ä½“çš„ãªæ•°å€¤

4. **Contextï¼ˆçŠ¶æ³ï¼‰** - æ³•å¾‹é©ç”¨åˆ¤æ–­ã«ã¯å¿…é ˆ
   - å…·ä½“çš„ãªçŠ¶æ³ã€ä½¿ç”¨æ–¹æ³•ã€ç›®çš„
   - è©²å½“ã™ã‚‹æ¡ä»¶ã‚„å‰æ

**å³æ ¼ãªåˆ¤å®šãƒ«ãƒ¼ãƒ«**:

âœ… **å…·ä½“çš„ã¨åˆ¤å®šã™ã‚‹æ¡ä»¶**:
- ç”¨èªã®å®šç¾©ã‚’èã„ã¦ã„ã‚‹ï¼ˆä¾‹ï¼šã€Œæ™¯å“é¡ã®å®šç¾©ã¯ï¼Ÿã€ï¼‰
- ç‰¹å®šã®æ¡æ–‡ã‚„åˆ¶åº¦ã®è§£èª¬ã‚’æ±‚ã‚ã¦ã„ã‚‹
- æ‰‹ç¶šãã®æ–¹æ³•ã‚’èã„ã¦ã„ã‚‹
- ä¸Šè¨˜ã®å¿…è¦æƒ…å ±ãŒã™ã¹ã¦å«ã¾ã‚Œã¦ã„ã‚‹å…·ä½“çš„ãªã‚±ãƒ¼ã‚¹ã®ç›¸è«‡

âŒ **æ›–æ˜§ã¨åˆ¤å®šã™ã‚‹æ¡ä»¶ï¼ˆä»¥ä¸‹ã®ã„ãšã‚Œã‹ã«è©²å½“ï¼‰**:
- ã€Œã€œã¯é©ç”¨ã•ã‚Œã‚‹ï¼Ÿã€ã€Œã€œã«è©²å½“ã™ã‚‹ï¼Ÿã€ã¨ã„ã†æ³•å¾‹é©ç”¨ã®åˆ¤æ–­ã‚’æ±‚ã‚ã¦ã„ã‚‹ãŒã€åˆ¤æ–­ã«å¿…è¦ãªå…·ä½“çš„æƒ…å ±ï¼ˆé‡‘é¡ã€ä¸»ä½“ã€çŠ¶æ³ãªã©ï¼‰ãŒä¸è¶³
- æŠ½è±¡çš„ãªä¸€èˆ¬åè©ã®ã¿ã§ã€å…·ä½“çš„ãªå†…å®¹ãŒä¸æ˜ï¼ˆä¾‹ï¼šã€Œé›»å­ãƒã‚±ãƒƒãƒˆã€ã€Œãƒã‚¤ãƒ³ãƒˆã€ã ã‘ã§ã¯ä¸ååˆ†ï¼‰
- ã€Œã«ã¤ã„ã¦æ•™ãˆã¦ã€ã€Œè©³ã—ãçŸ¥ã‚ŠãŸã„ã€ã ã‘ã§ç¯„å›²ãŒåºƒã™ãã‚‹
- æ³•å¾‹ã®é©ç”¨å¯å¦ã‚’èã„ã¦ã„ã‚‹ã®ã«ã€Whoï¼ˆèª°ãŒï¼‰ã‚„How muchï¼ˆã„ãã‚‰ï¼‰ãŒä¸æ˜

**ç‰¹ã«æ³¨æ„**:
- ã€Œ{law_type}ã€ã«é©ç”¨ã•ã‚Œã‚‹ã‹åˆ¤æ–­ã‚’æ±‚ã‚ã‚‹è³ªå•ã¯ã€åˆ¤æ–­ã«å¿…è¦ãªå…·ä½“çš„æƒ…å ±ãŒã™ã¹ã¦æƒã£ã¦ã„ãªã„é™ã‚Šæ›–æ˜§ã¨åˆ¤å®šã—ã¦ãã ã•ã„
- è³‡é‡‘æ±ºæ¸ˆæ³•ã‚„å°ç´™ç¨æ³•ãªã©é‡‘é¡åŸºæº–ãŒã‚ã‚‹æ³•å¾‹ã®å ´åˆã€é‡‘é¡æƒ…å ±ãŒãªã„é©ç”¨åˆ¤æ–­ã®è³ªå•ã¯å¿…ãšæ›–æ˜§ã¨åˆ¤å®šã—ã¦ãã ã•ã„

# è³ªå•
{question}

# å‡ºåŠ›å½¢å¼ï¼ˆä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼‰
{{
  "is_clear": true ã¾ãŸã¯ false,
  "missing_aspects": ["ä¸è¶³ã—ã¦ã„ã‚‹è¦³ç‚¹ã®ãƒªã‚¹ãƒˆ"],
  "clarifying_questions": ["å…·ä½“åŒ–ã®ãŸã‚ã®è³ªå•1", "å…·ä½“åŒ–ã®ãŸã‚ã®è³ªå•2", "å…·ä½“åŒ–ã®ãŸã‚ã®è³ªå•3"]
}}

**é‡è¦**: å¿…ãšJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
"""

# è¿½åŠ æƒ…å ±ã‚’å«ã‚ãŸè³ªå•ã®å†è©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
CLARITY_RECHECK_PROMPT = """
ã‚ãªãŸã¯æ³•å¾‹ç›¸è«‡ã«ãŠã‘ã‚‹è³ªå•ã®å…·ä½“æ€§ã‚’è©•ä¾¡ã™ã‚‹å³æ ¼ãªå°‚é–€å®¶ã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€åˆã«æ›–æ˜§ãªè³ªå•ã‚’ã—ã€è¿½åŠ æƒ…å ±ã‚’æä¾›ã—ã¾ã—ãŸã€‚
å…ƒã®è³ªå•ã¨è¿½åŠ æƒ…å ±ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ã€Œ{law_type}ã€ã«é–¢ã™ã‚‹æ³•å¾‹ç›¸è«‡ã¨ã—ã¦ååˆ†ã«å…·ä½“çš„ã«ãªã£ãŸã‹ã©ã†ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

# å…ƒã®è³ªå•
{original_question}

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæä¾›ã—ãŸè¿½åŠ æƒ…å ±
{additional_info}

**è©•ä¾¡åŸºæº–**:
æ³•å¾‹ã®é©ç”¨åˆ¤æ–­ã‚„æ³•çš„è©•ä¾¡ã‚’æ±‚ã‚ã‚‹è³ªå•ã®å ´åˆã€ä»¥ä¸‹ã®å…·ä½“çš„æƒ…å ±ãŒå¿…è¦ã§ã™ï¼š
- é‡‘é¡ãƒ»è¦æ¨¡ï¼ˆæ•°å€¤ï¼‰
- å…·ä½“çš„ãªä¸»ä½“ï¼ˆèª°ãŒã€ã©ã®ã‚ˆã†ãªç«‹å ´ã§ï¼‰
- å…·ä½“çš„ãªçŠ¶æ³ãƒ»è¡Œç‚ºã®å†…å®¹
- æ™‚æœŸãƒ»æœŸé–“ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

**åˆ¤å®šãƒ«ãƒ¼ãƒ«**:

âœ… **ååˆ†ã«å…·ä½“çš„ã¨åˆ¤å®šã™ã‚‹æ¡ä»¶**:
- ä¸Šè¨˜ã®å¿…è¦æƒ…å ±ãŒã™ã¹ã¦æä¾›ã•ã‚ŒãŸ
- æ³•å¾‹é©ç”¨ã®åˆ¤æ–­ã«å¿…è¦ãªå…·ä½“çš„ãªæ•°å€¤ã€ä¸»ä½“ã€çŠ¶æ³ãŒæ˜ç¢ºã«ãªã£ãŸ

âŒ **ã¾ã ä¸è¶³ã—ã¦ã„ã‚‹ã¨åˆ¤å®šã™ã‚‹æ¡ä»¶**:
- é‡è¦ãªæƒ…å ±ï¼ˆç‰¹ã«é‡‘é¡ã€ä¸»ä½“ã€å…·ä½“çš„çŠ¶æ³ï¼‰ãŒã¾ã ä¸è¶³ã—ã¦ã„ã‚‹
- æä¾›ã•ã‚ŒãŸæƒ…å ±ãŒæŠ½è±¡çš„ã§ã€åˆ¤æ–­ã«ä½¿ãˆãªã„

**ç‰¹ã«æ³¨æ„**:
- è³‡é‡‘æ±ºæ¸ˆæ³•ã‚„å°ç´™ç¨æ³•ãªã©é‡‘é¡åŸºæº–ãŒã‚ã‚‹æ³•å¾‹ã®å ´åˆã€é‡‘é¡æƒ…å ±ã¯å¿…é ˆ
- ã€Œäº‹æ¥­è€…ã€ã€Œä¼šç¤¾ã€ã ã‘ã§ã¯ä¸ååˆ†ãªå ´åˆãŒã‚ã‚Šã€äº‹æ¥­å½¢æ…‹ã‚„è¦æ¨¡ãŒå¿…è¦ãªã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹

# å‡ºåŠ›å½¢å¼ï¼ˆä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼‰
{{
  "is_now_clear": true ã¾ãŸã¯ false,
  "still_missing_aspects": ["ã¾ã ä¸è¶³ã—ã¦ã„ã‚‹è¦³ç‚¹ã®ãƒªã‚¹ãƒˆï¼ˆç©ºã®å ´åˆã¯ååˆ†ï¼‰"],
  "next_clarifying_questions": ["ã•ã‚‰ã«å¿…è¦ãªè³ªå•1", "è³ªå•2", "è³ªå•3"],
  "combined_question": "å…ƒã®è³ªå•ã¨è¿½åŠ æƒ…å ±ã‚’çµ±åˆã—ãŸå®Œå…¨ãªè³ªå•æ–‡"
}}

**é‡è¦**: å¿…ãšJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
"""

# å›ç­”ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
PROMPT_TEMPLATE = """
ã‚ãªãŸã¯æ³•å¾‹ã‚„FAQã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã™ã‚‹è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»Šå›ã®è³ªå•ã¯ã€Œ{law_type}ã€ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã€‚

**é‡è¦**: å›ç­”ã¯å¿…ãšã€Œ{law_type}ã€ã®è¦³ç‚¹ã‹ã‚‰è¡Œã£ã¦ãã ã•ã„ã€‚
ä»–ã®æ³•å¾‹ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ã€Œ{law_type}ã€ã«é–¢é€£ã™ã‚‹éƒ¨åˆ†ã®ã¿ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚

**å›ç­”ã®æ§‹æˆ**:
ã¾ãšã€ŒğŸ“Œ è¦ç´„ ({law_type})ã€ã¨ã—ã¦ã€æœ€ã‚‚é¡ä¼¼åº¦ãŒé«˜ã„å‚ç…§æ–‡æ›¸ï¼ˆ[å‚ç…§1]ã¾ãŸã¯[å‚ç…§2]ï¼‰ã‹ã‚‰ã€è³ªå•ã«ç›´æ¥é–¢é€£ã™ã‚‹éƒ¨åˆ†ã‚’æŠœç²‹ãƒ»è¦ç´„ã—ã¦ãã ã•ã„ã€‚
ã“ã®è¦ç´„ã§ã¯ã€æ–‡æ›¸ã®å†…å®¹ã‚’ãã®ã¾ã¾ä¼ãˆã€ç‹¬è‡ªã®è§£é‡ˆã‚„æ¨æ¸¬ã¯ä¸€åˆ‡åŠ ãˆãªã„ã§ãã ã•ã„ã€‚
ãã®å¾Œã€è©³ç´°ãªèª¬æ˜ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

**é‡è¦ãªæŒ‡ç¤º**:
1. **è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³**:
   - å†’é ­ã«ã€ŒğŸ“Œ è¦ç´„ ({law_type})ã€ã¨ã—ã¦ã€å‚ç…§æ–‡æ›¸ã‹ã‚‰ã®ç›´æ¥çš„ãªå†…å®¹ã®ã¿ã‚’è¨˜è¼‰
   - æ–‡æ›¸ã«æ›¸ã‹ã‚Œã¦ã„ãªã„ã“ã¨ã¯æ›¸ã‹ãªã„
   - ç‹¬è‡ªã®è§£é‡ˆã€æ¨æ¸¬ã€ä¸€èˆ¬åŒ–ã¯è¡Œã‚ãªã„
   - å¿…ãšå‡ºå…¸ï¼ˆ[å‚ç…§1]ãªã©ï¼‰ã‚’æ˜è¨˜

2. **è©³ç´°èª¬æ˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³**:
   - å„æ–‡ã‚„æ®µè½ã®æœ€å¾Œã«ã€ãã®æƒ…å ±ãŒã©ã®å‚ç…§ã‹ã‚‰æ¥ã¦ã„ã‚‹ã‹ã‚’ï¼ˆ[å‚ç…§1]ï¼‰ã®ã‚ˆã†ã«è¨˜è¼‰
   - è¤‡æ•°ã®å‚ç…§ã‹ã‚‰æƒ…å ±ã‚’å¾—ãŸå ´åˆã¯ã€ï¼ˆ[å‚ç…§1, 2]ï¼‰ã®ã‚ˆã†ã«è¨˜è¼‰
   - æ³•å¾‹æ¡æ–‡ã€æ–½è¡Œè¦å‰‡ã€FAQ ãã‚Œãã‚Œã®æƒ…å ±ã‚’åŒºåˆ¥ã—ã¦æ´»ç”¨

3. **æ›¸å¼**:
   - Slackç”¨ã«ã€ç®‡æ¡æ›¸ãã‚„æ®µè½ã‚’è¦‹ã‚„ã™ãæ•´å½¢
   - å…¨ãé–¢é€£ã™ã‚‹æƒ…å ±ãŒãªã„å ´åˆã¯ã€ã€Œæä¾›ã•ã‚ŒãŸæƒ…å ±ã«ã¯ã€ã“ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€ã¨ç­”ãˆã‚‹

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
{context}

# è³ªå•
{question}

# å›ç­”ï¼ˆå¿…ãšä¸Šè¨˜ã®æ§‹æˆã«å¾“ã£ã¦ãã ã•ã„ï¼‰
"""

# Slack Appã®åˆæœŸåŒ–
app = App(token=SLACK_BOT_TOKEN)


# ãƒ™ã‚¯ãƒˆãƒ«DBã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®åˆæœŸåŒ–
def load_vectordb_with_hybrid_search():
    """ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢retrieverã‚’ä½œæˆ"""
    print("  [1/4] åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    embedding_model = OpenAIEmbeddings(
        model="text-embedding-3-large",
        openai_api_key=OPENAI_API_KEY
    )
    
    print("  [2/4] ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ä¸­...")
    vectordb = Chroma(
        persist_directory=CHROMA_DB_DIR,
        embedding_function=embedding_model
    )
    
    print("  [3/4] å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­ï¼ˆBM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã®ãŸã‚ï¼‰...")
    print("  â€» ã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")
    
    print("  [4/4] ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢retrieverã‚’æ§‹ç¯‰ä¸­...")
    hybrid_retriever = HybridSearchRetriever(
        vectordb=vectordb,
        alpha=0.5  # BM25ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’åŒã˜é‡ã¿ã§
    )
    
    print("  âœ“ åˆæœŸåŒ–å®Œäº†")
    return hybrid_retriever


def format_docs(docs):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦ã€å‚ç…§ç•ªå·ã‚’ä»˜ä¸"""
    context_parts = []
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get('source', 'ä¸æ˜')
        chunk_id = doc.metadata.get('chunk_id', 'ä¸æ˜')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çŸ­ç¸®
        if 'Q&A' in source:
            source_type = "FAQ"
        elif 'æ–½è¡Œè¦å‰‡' in source:
            source_type = "æ–½è¡Œè¦å‰‡"
        elif 'ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•.pdf' in source:
            source_type = "æ™¯è¡¨æ³•"
        else:
            source_type = source
        
        context_parts.append(
            f"[å‚ç…§{i}] (å‡ºå…¸: {source_type}, {source}, ID: {chunk_id})\n{doc.page_content}\n"
        )
    
    return "\n".join(context_parts)


def check_question_clarity(question: str, law_type: str) -> dict:
    """
    è³ªå•ã®å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ›–æ˜§ãªå ´åˆã¯è¿½åŠ è³ªå•ã‚’ç”Ÿæˆ
    
    Returns:
        dict: {
            "is_clear": bool,
            "missing_aspects": list,
            "clarifying_questions": list
        }
    """
    # LLMã®åˆæœŸåŒ–ï¼ˆå³æ ¼ãªåˆ¤å®šã®ãŸã‚ä½æ¸©åº¦ï¼‰
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1,  # å³æ ¼ãªåˆ¤å®šã®ãŸã‚ä½æ¸©åº¦
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = PromptTemplate.from_template(CLARITY_CHECK_PROMPT)
    
    # ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    chain = (
        {
            "question": lambda x: x,
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    try:
        # LLMã§è³ªå•ã®å…·ä½“æ€§ã‚’åˆ¤å®š
        result = chain.invoke({"question": question, "law_type": law_type})
        
        print(f"  [LLMåˆ¤å®šçµæœï¼ˆç”Ÿï¼‰]: {result[:200]}...")  # ãƒ‡ãƒãƒƒã‚°ç”¨
        
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ï¼‰
        json_match = re.search(r'\{[^{}]*"is_clear"[^{}]*\}', result, re.DOTALL)
        if json_match:
            result = json_match.group(0)
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        clarity_result = json.loads(result)
        
        print(f"  [åˆ¤å®šçµæœ] is_clear={clarity_result.get('is_clear')}, missing={clarity_result.get('missing_aspects')}")
        
        return clarity_result
        
    except Exception as e:
        print(f"è³ªå•ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"  ã‚¨ãƒ©ãƒ¼è©³ç´°: result={result if 'result' in locals() else 'N/A'}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ›–æ˜§ã¨åˆ¤å®šï¼ˆå®‰å…¨å´ã«å€’ã™ï¼‰
        return {
            "is_clear": False,
            "missing_aspects": ["ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸ"],
            "clarifying_questions": [
                "è³ªå•ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«è¨˜è¿°ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ",
                "å…·ä½“çš„ãªé‡‘é¡ã‚„æ•°å€¤ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "èª°ãŒã€ã©ã®ã‚ˆã†ãªçŠ¶æ³ã§è¡Œã†ã“ã¨ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ"
            ]
        }


def recheck_question_with_additional_info(original_question: str, additional_info: list, law_type: str) -> dict:
    """
    è¿½åŠ æƒ…å ±ã‚’å«ã‚ã¦è³ªå•ã®å…·ä½“æ€§ã‚’å†ãƒã‚§ãƒƒã‚¯
    
    Returns:
        dict: {
            "is_now_clear": bool,
            "still_missing_aspects": list,
            "next_clarifying_questions": list,
            "combined_question": str
        }
    """
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1,
    )
    
    # è¿½åŠ æƒ…å ±ã‚’æ•´å½¢
    additional_info_text = "\n".join([f"- {info}" for info in additional_info])
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = PromptTemplate.from_template(CLARITY_RECHECK_PROMPT)
    
    # ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    chain = (
        {
            "original_question": lambda x: original_question,
            "additional_info": lambda x: additional_info_text,
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    try:
        # LLMã§å†è©•ä¾¡
        result = chain.invoke({"original_question": original_question, "additional_info": additional_info_text, "law_type": law_type})
        
        print(f"  [å†è©•ä¾¡çµæœï¼ˆç”Ÿï¼‰]: {result[:200]}...")
        
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'\{[^{}]*"is_now_clear"[^{}]*\}', result, re.DOTALL)
        if json_match:
            result = json_match.group(0)
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        recheck_result = json.loads(result)
        
        print(f"  [å†è©•ä¾¡åˆ¤å®š] is_now_clear={recheck_result.get('is_now_clear')}, still_missing={recheck_result.get('still_missing_aspects')}")
        
        return recheck_result
        
    except Exception as e:
        print(f"è³ªå•ã®å†è©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"  ã‚¨ãƒ©ãƒ¼è©³ç´°: result={result if 'result' in locals() else 'N/A'}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¸è¶³ã¨åˆ¤å®š
        return {
            "is_now_clear": False,
            "still_missing_aspects": ["ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸ"],
            "next_clarifying_questions": [
                "ã‚‚ã†å°‘ã—å…·ä½“çš„ãªæƒ…å ±ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"
            ],
            "combined_question": f"{original_question} ã€è¿½åŠ æƒ…å ±ã€‘ {'; '.join(additional_info)}"
        }


def create_law_selection_blocks(question: str):
    """æ³•å¾‹é¸æŠç”¨ã®ãƒœã‚¿ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆ"""
    return [
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ğŸ“‹ è³ªå•ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸ:\n> {question}\n\nã©ã®æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã‹ï¼Ÿ"
            }
        },
        {
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": "ğŸ“œ æ™¯è¡¨æ³•"},
                    "value": f"keihyouhou|||{question}",
                    "action_id": "select_law_keihyouhou"
                },
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": "ğŸ’° è³‡é‡‘æ±ºæ¸ˆæ³•"},
                    "value": f"shikin_kessai|||{question}",
                    "action_id": "select_law_shikin_kessai"
                },
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": "ğŸ” å€‹äººæƒ…å ±ä¿è­·æ³•"},
                    "value": f"kojin_jouhou|||{question}",
                    "action_id": "select_law_kojin_jouhou"
                },
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": "ğŸ“ å°ç´™ç¨æ³•"},
                    "value": f"inshi_zei|||{question}",
                    "action_id": "select_law_inshi_zei"
                }
            ]
        }
    ]


def generate_answer_directly(query: str, hybrid_retriever, law_type: str = "æ™¯è¡¨æ³•"):
    """è³ªå•ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥å›ç­”ã‚’ç”Ÿæˆï¼ˆè¿½åŠ æƒ…å ±çµ±åˆå¾Œç”¨ï¼‰"""
    
    print(f"  [ç›´æ¥å›ç­”ç”Ÿæˆ] è³ªå•: {query}")
    
    # 1. æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆæ³•å¾‹åã‚’è¿½åŠ ã—ã¦ç²¾åº¦å‘ä¸Šï¼‰
    enhanced_query = f"{law_type} {query}"
    
    # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆå¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    docs_and_scores = hybrid_retriever.search(enhanced_query, k=TOP_K_RESULTS * 3)
    
    # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆé¸æŠã•ã‚ŒãŸæ³•å¾‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰
    relevant_sources = LAW_SOURCE_MAPPING.get(law_type, [])
    if relevant_sources:
        filtered_docs = [
            (doc, score) for doc, score in docs_and_scores 
            if any(source in doc.metadata.get('source', '') for source in relevant_sources)
        ][:TOP_K_RESULTS]
    else:
        filtered_docs = docs_and_scores[:TOP_K_RESULTS]
    
    docs = [doc for doc, score in filtered_docs]
    
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.2,
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
    
    # RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    rag_chain = (
        {
            "context": lambda x: format_docs(docs),
            "question": lambda x: query,  # å…ƒã®ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # å›ç­”ã®ç”Ÿæˆ
    answer = rag_chain.invoke(query)
    
    # å‚ç…§å…ƒæƒ…å ±ã®æ•´å½¢ï¼ˆSlackç”¨ï¼‰
    references = []
    for i, (doc, score) in enumerate(filtered_docs, 1):
        source = doc.metadata.get('source', 'ä¸æ˜')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çŸ­ç¸®
        if 'Q&A' in source:
            source_label = "FAQ"
        elif 'æ–½è¡Œè¦å‰‡' in source or 'æ–½è¡Œä»¤' in source:
            source_label = "æ–½è¡Œè¦å‰‡ãƒ»æ–½è¡Œä»¤"
        elif 'ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•.pdf' in source:
            source_label = "ğŸ“œ æ™¯è¡¨æ³•"
        elif 'è³‡é‡‘æ±ºæ¸ˆã«é–¢ã™ã‚‹æ³•å¾‹.pdf' in source:
            source_label = "ğŸ’° è³‡é‡‘æ±ºæ¸ˆæ³•"
        elif 'å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹' in source:
            source_label = "ğŸ” å€‹äººæƒ…å ±ä¿è­·æ³•"
        elif 'å°ç´™ç¨æ³•.pdf' in source:
            source_label = "ğŸ“ å°ç´™ç¨æ³•"
        else:
            source_label = source
        
        hybrid_score = doc.metadata.get('hybrid_score', 0)
        references.append(f"[{i}] {source_label} (ã‚¹ã‚³ã‚¢: {hybrid_score:.3f})")
    
    return answer, references


def generate_answer(query: str, hybrid_retriever, law_type: str = "æ™¯è¡¨æ³•"):
    """è³ªå•ã«å¯¾ã—ã¦å›ç­”ã‚’ç”Ÿæˆï¼ˆæ³•å¾‹ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»æ‹¡å¼µï¼‰"""
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: è³ªå•ã®å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    print(f"  [è³ªå•ã®å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...] è³ªå•: {query}")
    clarity_result = check_question_clarity(query, law_type)
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: è³ªå•ãŒæ›–æ˜§ãªå ´åˆã¯è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°
    if not clarity_result.get("is_clear", True):
        print(f"  [åˆ¤å®š] è³ªå•ãŒæ›–æ˜§ - è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½")
        
        missing_aspects = clarity_result.get("missing_aspects", [])
        clarifying_questions = clarity_result.get("clarifying_questions", [])
        
        # è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
        clarification_message = f"â“ **è³ªå•ã‚’å…·ä½“åŒ–ã•ã›ã¦ãã ã•ã„**\n\n"
        clarification_message += f"ã”è³ªå•ã®å†…å®¹ã‚’ã‚ˆã‚Šæ­£ç¢ºã«ç†è§£ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ\n\n"
        
        for i, q in enumerate(clarifying_questions[:3], 1):
            clarification_message += f"{i}. {q}\n"
        
        clarification_message += f"\nã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’ã„ãŸã ã‘ã‚Œã°ã€**{law_type}**ã®è¦³ç‚¹ã‹ã‚‰é©åˆ‡ãªå›ç­”ã‚’æä¾›ã§ãã¾ã™ã€‚"
        
        # è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°ã®å ´åˆã¯å‚ç…§ãªã—
        return clarification_message, []
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: è³ªå•ãŒå…·ä½“çš„ãªå ´åˆã¯å›ç­”ã‚’ç”Ÿæˆ
    print(f"  [åˆ¤å®š] è³ªå•ãŒå…·ä½“çš„ - å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™")
    
    # 1. æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆæ³•å¾‹åã‚’è¿½åŠ ã—ã¦ç²¾åº¦å‘ä¸Šï¼‰
    enhanced_query = f"{law_type} {query}"
    
    # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆå¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    docs_and_scores = hybrid_retriever.search(enhanced_query, k=TOP_K_RESULTS * 3)
    
    # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆé¸æŠã•ã‚ŒãŸæ³•å¾‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰
    relevant_sources = LAW_SOURCE_MAPPING.get(law_type, [])
    if relevant_sources:
        filtered_docs = [
            (doc, score) for doc, score in docs_and_scores 
            if any(source in doc.metadata.get('source', '') for source in relevant_sources)
        ][:TOP_K_RESULTS]
    else:
        filtered_docs = docs_and_scores[:TOP_K_RESULTS]
    
    docs = [doc for doc, score in filtered_docs]
    
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.2,
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
    
    # RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    rag_chain = (
        {
            "context": lambda x: format_docs(docs),
            "question": lambda x: query,  # å…ƒã®ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # å›ç­”ã®ç”Ÿæˆ
    answer = rag_chain.invoke(query)
    
    # å‚ç…§å…ƒæƒ…å ±ã®æ•´å½¢ï¼ˆSlackç”¨ï¼‰
    references = []
    for i, (doc, score) in enumerate(filtered_docs, 1):
        source = doc.metadata.get('source', 'ä¸æ˜')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çŸ­ç¸®
        if 'Q&A' in source:
            source_label = "FAQ"
        elif 'æ–½è¡Œè¦å‰‡' in source or 'æ–½è¡Œä»¤' in source:
            source_label = "æ–½è¡Œè¦å‰‡ãƒ»æ–½è¡Œä»¤"
        elif 'ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•.pdf' in source:
            source_label = "ğŸ“œ æ™¯è¡¨æ³•"
        elif 'è³‡é‡‘æ±ºæ¸ˆã«é–¢ã™ã‚‹æ³•å¾‹.pdf' in source:
            source_label = "ğŸ’° è³‡é‡‘æ±ºæ¸ˆæ³•"
        elif 'å€‹äººæƒ…å ±ã®ä¿è­·ã«é–¢ã™ã‚‹æ³•å¾‹' in source:
            source_label = "ğŸ” å€‹äººæƒ…å ±ä¿è­·æ³•"
        elif 'å°ç´™ç¨æ³•.pdf' in source:
            source_label = "ğŸ“ å°ç´™ç¨æ³•"
        else:
            source_label = source
        
        hybrid_score = doc.metadata.get('hybrid_score', 0)
        references.append(f"[{i}] {source_label} (ã‚¹ã‚³ã‚¢: {hybrid_score:.3f})")
    
    return answer, references


# Slackã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.event("app_mention")
def handle_mention(event, say):
    """ãƒœãƒƒãƒˆãŒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ™‚ã®å‡¦ç†"""
    try:
        # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’é™¤å»ã—ã¦è³ªå•ã‚’æŠ½å‡º
        text = event['text']
        question = re.sub(r'<@[A-Z0-9]+>', '', text).strip()
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ç”¨ï¼‰
        thread_ts = event['ts']
        
        if not question:
            say("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹: @FAQ Bot æ™¯å“é¡ã®å®šç¾©ã‚’æ•™ãˆã¦ãã ã•ã„", thread_ts=thread_ts)
            return
        
        # æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        say(
            blocks=create_law_selection_blocks(question),
            text=f"ã©ã®æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã‹ï¼Ÿ\nè³ªå•: {question}",
            thread_ts=thread_ts
        )
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã‚‚ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        thread_ts = event.get('ts')
        say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", thread_ts=thread_ts)


@app.message("")
def handle_message(message, say, client):
    """DMã‚„é€šå¸¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¸ã®å¿œç­”ã€ãŠã‚ˆã³ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®è¿½åŠ æƒ…å ±ã®å‡¦ç†"""
    print(f"  [handle_messageå‘¼ã³å‡ºã—] message={message.get('text', '')[:50]}, channel_type={message.get('channel_type', 'N/A')}, bot_id={message.get('bot_id', 'N/A')}, thread_ts={message.get('thread_ts', 'N/A')}")
    
    # ãƒœãƒƒãƒˆã®æŠ•ç¨¿ã¯ç„¡è¦–
    if message.get('bot_id'):
        print(f"  [ã‚¹ã‚­ãƒƒãƒ—] ãƒœãƒƒãƒˆã®æŠ•ç¨¿")
        return
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ãƒã‚§ãƒƒã‚¯
    thread_ts = message.get('thread_ts')
    print(f"  [ãƒã‚§ãƒƒã‚¯] thread_ts={thread_ts}, contexts={list(thread_contexts.keys())}")
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯è¿½åŠ æƒ…å ±ã¨ã—ã¦å‡¦ç†
    if thread_ts and thread_ts in thread_contexts:
        try:
            context = thread_contexts[thread_ts]
            user_response = message['text'].strip()
            
            if not user_response:
                return
            
            print(f"  [ã‚¹ãƒ¬ãƒƒãƒ‰å†…å¿œç­”æ¤œçŸ¥] thread_ts={thread_ts}, response={user_response}")
            
            # è¿½åŠ æƒ…å ±ã‚’è¨˜éŒ²
            context['additional_info'].append(user_response)
            
            # ã€Œç¢ºèªä¸­ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
            say(f"ğŸ¤” è¿½åŠ æƒ…å ±ã‚’ç¢ºèªã—ã¦ã„ã¾ã™...\n> {user_response}", thread_ts=thread_ts)
            
            # è¿½åŠ æƒ…å ±ã‚’å«ã‚ã¦å†è©•ä¾¡
            recheck_result = recheck_question_with_additional_info(
                context['original_question'],
                context['additional_info'],
                context['law_type']
            )
            
            # ååˆ†ã«å…·ä½“çš„ã«ãªã£ãŸå ´åˆ
            if recheck_result.get('is_now_clear', False):
                combined_question = recheck_result.get('combined_question', context['original_question'])
                
                say(
                    f"âœ… **æƒ…å ±ãŒæƒã„ã¾ã—ãŸï¼å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™**\n\nçµ±åˆã•ã‚ŒãŸè³ªå•:\n> {combined_question}",
                    thread_ts=thread_ts
                )
                
                # çµ±åˆã•ã‚ŒãŸè³ªå•ã§å›ç­”ã‚’ç”Ÿæˆï¼ˆå…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥å›ç­”ï¼‰
                print(f"  [çµ±åˆè³ªå•ã§å›ç­”ç”Ÿæˆ] {combined_question}")
                law_type = context['law_type']
                answer, references = generate_answer_directly(combined_question, hybrid_retriever, law_type)
                
                # å›ç­”ã‚’é€ä¿¡
                response_text = f"*ğŸ“ å›ç­” ({law_type}):*\n{answer}\n\n*ğŸ“š å‚ç…§å…ƒ:*\n"
                for ref in references:
                    response_text += f"  â€¢ {ref}\n"
                
                say(response_text, thread_ts=thread_ts)
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
                del thread_contexts[thread_ts]
                print(f"  [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‰Šé™¤] thread_ts={thread_ts}")
                
            else:
                # ã¾ã ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯è¿½åŠ è³ªå•
                still_missing = recheck_result.get('still_missing_aspects', [])
                next_questions = recheck_result.get('next_clarifying_questions', [])
                
                clarification_message = f"â“ **ã‚‚ã†å°‘ã—æƒ…å ±ãŒå¿…è¦ã§ã™**\n\n"
                clarification_message += f"ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ\n\n"
                
                for i, q in enumerate(next_questions[:3], 1):
                    clarification_message += f"{i}. {q}\n"
                
                clarification_message += f"\nä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±: {', '.join(still_missing)}"
                
                say(clarification_message, thread_ts=thread_ts)
            
            return
            
        except Exception as e:
            print(f"ã‚¹ãƒ¬ãƒƒãƒ‰å†…ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", thread_ts=thread_ts)
            return
    
    # ãƒãƒ£ãƒãƒ«ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
    channel_type = message.get('channel_type', '')
    
    # DMã®å ´åˆã®ã¿å¿œç­”
    if channel_type == 'im':
        try:
            question = message['text'].strip()
            
            if not question:
                return
            
            # æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ã‚’é€ä¿¡
            say(
                blocks=create_law_selection_blocks(question),
                text=f"ã©ã®æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã‹ï¼Ÿ\nè³ªå•: {question}"
            )
            
        except Exception as e:
            say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


# ãƒœã‚¿ãƒ³ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.action(re.compile("select_law_.*"))
def handle_law_selection(ack, body, say):
    """æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸæ™‚ã®å‡¦ç†"""
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª
    ack()
    
    try:
        # ãƒœã‚¿ãƒ³ã®å€¤ã‹ã‚‰æ³•å¾‹ã‚¿ã‚¤ãƒ—ã¨è³ªå•ã‚’å–å¾—
        action_value = body['actions'][0]['value']
        law_key, question = action_value.split('|||', 1)
        law_type = LAW_TYPES.get(law_key, "æ™¯è¡¨æ³•")
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—
        thread_ts = body['message']['thread_ts'] if 'thread_ts' in body['message'] else body['message']['ts']
        
        # ã€Œè€ƒãˆä¸­ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        say(f"ğŸ¤” {law_type}ã«é–¢ã™ã‚‹è³ªå•ã¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆä¸­...\n> {question}", thread_ts=thread_ts)
        
        # å›ç­”ã‚’ç”Ÿæˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä»˜ãï¼‰
        answer, references = generate_answer(question, hybrid_retriever, law_type)
        
        # å›ç­”ãŒè¿½åŠ è³ªå•ï¼ˆå‚ç…§ãªã—ï¼‰ã®å ´åˆã€ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
        if not references:  # è¿½åŠ è³ªå•ã®å ´åˆ
            thread_contexts[thread_ts] = {
                "original_question": question,
                "law_type": law_type,
                "additional_info": [],
                "last_interaction": body.get('message', {}).get('ts')
            }
            print(f"  [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜] thread_ts={thread_ts}, question={question}, law_type={law_type}")
        
        # å›ç­”ã‚’æ•´å½¢ï¼ˆSlackç”¨ï¼‰
        if references:
            response_text = f"*ğŸ“ å›ç­” ({law_type}):*\n{answer}\n\n*ğŸ“š å‚ç…§å…ƒ:*\n"
            for ref in references:
                response_text += f"  â€¢ {ref}\n"
        else:
            # è¿½åŠ è³ªå•ã®å ´åˆã¯ãã®ã¾ã¾
            response_text = answer
        
        # å›ç­”ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        say(response_text, thread_ts=thread_ts)
        
    except Exception as e:
        thread_ts = body['message'].get('thread_ts') or body['message'].get('ts')
        say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", thread_ts=thread_ts)


if __name__ == "__main__":
    # ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    if not SLACK_BOT_TOKEN or not SLACK_APP_TOKEN:
        print("ã‚¨ãƒ©ãƒ¼: SLACK_BOT_TOKEN ã¨ SLACK_APP_TOKEN ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    if not OPENAI_API_KEY or not GOOGLE_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEY ã¨ GOOGLE_API_KEY ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    if not os.path.exists(CHROMA_DB_DIR):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ™ã‚¯ãƒˆãƒ«DB ({CHROMA_DB_DIR}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ã¾ãš prepare_database_openai.py ã‚’å®Ÿè¡Œã—ã¦ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã—ã¦ãã ã•ã„")
        exit(1)
    
    # ãƒ™ã‚¯ãƒˆãƒ«DBã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®åˆæœŸåŒ–
    print("FAQ Bot (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç‰ˆ) ã‚’èµ·å‹•ä¸­...")
    print(f"  - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ä¸Šä½{TOP_K_RESULTS}ä»¶ã‚’å–å¾—")
    print(f"  - æ³•å¾‹åˆ¥ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æœ‰åŠ¹")
    hybrid_retriever = load_vectordb_with_hybrid_search()
    
    print("\n" + "="*60)
    print("âœ“ FAQ Bot (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç‰ˆ) ãŒèµ·å‹•ã—ã¾ã—ãŸ")
    print("="*60)
    print("ãƒãƒ£ãƒãƒ«ã§ @FAQ Bot ã‚’ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã—ã¦è³ªå•ã—ã¦ãã ã•ã„")
    print("å¯¾å¿œæ³•å¾‹: æ™¯è¡¨æ³•ã€è³‡é‡‘æ±ºæ¸ˆæ³•ã€å€‹äººæƒ…å ±ä¿è­·æ³•ã€å°ç´™ç¨æ³•")
    print("BM25 + ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    print("\nçµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    print("="*60 + "\n")
    
    # Socket Modeã§èµ·å‹•
    handler = SocketModeHandler(app, SLACK_APP_TOKEN)
    handler.start()

