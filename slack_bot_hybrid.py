#!/usr/bin/env python3
"""
FAQ Bot for Slack with Hybrid Search
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸSlack Bot

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿:
- è¨­å®šã¯config.pyã«åˆ†é›¢
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯prompts/ã«åˆ†é›¢
- å…±é€šé–¢æ•°ã¯utils.pyã«åˆ†é›¢
"""

import os
import re
import json
from typing import Tuple, List, Dict

from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler

from langchain_openai import OpenAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

from hybrid_search import HybridSearchRetriever

# è¨­å®šã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import (
    SLACK_BOT_TOKEN,
    SLACK_APP_TOKEN,
    OPENAI_API_KEY,
    GOOGLE_API_KEY,
    CHROMA_DB_DIR,
    TOP_K_RESULTS,
    SEARCH_MULTIPLIER,
    MAX_CLARIFYING_QUESTIONS,
    CLARITY_CHECK_TEMPERATURE,
    ANSWER_GENERATION_TEMPERATURE,
    LAW_TYPES,
    LAW_SOURCE_MAPPING,
    EMBEDDING_MODEL,
    GENERATION_MODEL,
    HEALTH_CHECK_FILE
)

from utils import (
    get_clarity_check_prompt,
    get_clarity_recheck_prompt,
    get_answer_generation_prompt,
    format_docs,
    format_references,
    create_clarification_message,
    create_further_clarification_message,
    format_response_with_references
)

# ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ï¼ˆè¿½åŠ è³ªå•ã®å±¥æ­´ã‚’ä¿æŒï¼‰
thread_contexts: Dict[str, Dict] = {}

# Slack Appã®åˆæœŸåŒ–
app = App(token=SLACK_BOT_TOKEN)


# ========================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
# ========================

def load_vectordb_with_hybrid_search():
    """ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢retrieverã‚’ä½œæˆ"""
    print("  [1/4] åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    embedding_model = OpenAIEmbeddings(
        model=EMBEDDING_MODEL,
        openai_api_key=OPENAI_API_KEY
    )
    
    print("  [2/4] ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ä¸­...")
    vectordb = Chroma(
        persist_directory=CHROMA_DB_DIR,
        embedding_function=embedding_model
    )
    
    print("  [3/4] å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­ï¼ˆBM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã®ãŸã‚ï¼‰...")
    print("  â€» ã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")
    
    print("  [4/4] ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢retrieverã‚’æ§‹ç¯‰ä¸­...")
    hybrid_retriever = HybridSearchRetriever(
        vectordb=vectordb,
        alpha=0.5  # BM25ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’åŒã˜é‡ã¿ã§
    )
    
    print("  âœ“ åˆæœŸåŒ–å®Œäº†")
    return hybrid_retriever


# ========================
# è³ªå•ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯
# ========================


def check_question_clarity(question: str, law_type: str) -> dict:
    """
    è³ªå•ã®å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ›–æ˜§ãªå ´åˆã¯è¿½åŠ è³ªå•ã‚’ç”Ÿæˆ
    
    Returns:
        dict: {
            "is_clear": bool,
            "missing_aspects": list,
            "clarifying_questions": list
        }
    """
    # LLMã®åˆæœŸåŒ–ï¼ˆå³æ ¼ãªåˆ¤å®šã®ãŸã‚ä½æ¸©åº¦ï¼‰
    llm = ChatGoogleGenerativeAI(
        model=GENERATION_MODEL,
        google_api_key=GOOGLE_API_KEY,
        temperature=CLARITY_CHECK_TEMPERATURE,
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆï¼ˆutilsçµŒç”±ã§èª­ã¿è¾¼ã¿ï¼‰
    prompt = PromptTemplate.from_template(get_clarity_check_prompt())
    
    # ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    chain = (
        {
            "question": lambda x: x,
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    try:
        # LLMã§è³ªå•ã®å…·ä½“æ€§ã‚’åˆ¤å®š
        result = chain.invoke({"question": question, "law_type": law_type})
        
        print(f"  [LLMåˆ¤å®šçµæœï¼ˆç”Ÿï¼‰]: {result[:200]}...")  # ãƒ‡ãƒãƒƒã‚°ç”¨
        
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ï¼‰
        json_match = re.search(r'\{[^{}]*"is_clear"[^{}]*\}', result, re.DOTALL)
        if json_match:
            result = json_match.group(0)
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        clarity_result = json.loads(result)
        
        print(f"  [åˆ¤å®šçµæœ] is_clear={clarity_result.get('is_clear')}, missing={clarity_result.get('missing_aspects')}")
        
        return clarity_result
        
    except Exception as e:
        print(f"è³ªå•ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"  ã‚¨ãƒ©ãƒ¼è©³ç´°: result={result if 'result' in locals() else 'N/A'}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ›–æ˜§ã¨åˆ¤å®šï¼ˆå®‰å…¨å´ã«å€’ã™ï¼‰
        return {
            "is_clear": False,
            "missing_aspects": ["ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸ"],
            "clarifying_questions": [
                "è³ªå•ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«è¨˜è¿°ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ",
                "å…·ä½“çš„ãªé‡‘é¡ã‚„æ•°å€¤ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "èª°ãŒã€ã©ã®ã‚ˆã†ãªçŠ¶æ³ã§è¡Œã†ã“ã¨ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ"
            ]
        }


def recheck_question_with_additional_info(original_question: str, additional_info: list, law_type: str) -> dict:
    """
    è¿½åŠ æƒ…å ±ã‚’å«ã‚ã¦è³ªå•ã®å…·ä½“æ€§ã‚’å†ãƒã‚§ãƒƒã‚¯
    
    Returns:
        dict: {
            "is_now_clear": bool,
            "still_missing_aspects": list,
            "next_clarifying_questions": list,
            "combined_question": str
        }
    """
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model=GENERATION_MODEL,
        google_api_key=GOOGLE_API_KEY,
        temperature=CLARITY_CHECK_TEMPERATURE,
    )
    
    # è¿½åŠ æƒ…å ±ã‚’æ•´å½¢
    additional_info_text = "\n".join([f"- {info}" for info in additional_info])
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆï¼ˆutilsçµŒç”±ã§èª­ã¿è¾¼ã¿ï¼‰
    prompt = PromptTemplate.from_template(get_clarity_recheck_prompt())
    
    # ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    chain = (
        {
            "original_question": lambda x: original_question,
            "additional_info": lambda x: additional_info_text,
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    try:
        # LLMã§å†è©•ä¾¡
        result = chain.invoke({"original_question": original_question, "additional_info": additional_info_text, "law_type": law_type})
        
        print(f"  [å†è©•ä¾¡çµæœï¼ˆç”Ÿï¼‰]: {result[:200]}...")
        
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'\{[^{}]*"is_now_clear"[^{}]*\}', result, re.DOTALL)
        if json_match:
            result = json_match.group(0)
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        recheck_result = json.loads(result)
        
        print(f"  [å†è©•ä¾¡åˆ¤å®š] is_now_clear={recheck_result.get('is_now_clear')}, still_missing={recheck_result.get('still_missing_aspects')}")
        
        return recheck_result
        
    except Exception as e:
        print(f"è³ªå•ã®å†è©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"  ã‚¨ãƒ©ãƒ¼è©³ç´°: result={result if 'result' in locals() else 'N/A'}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¸è¶³ã¨åˆ¤å®š
        return {
            "is_now_clear": False,
            "still_missing_aspects": ["ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸ"],
            "next_clarifying_questions": [
                "ã‚‚ã†å°‘ã—å…·ä½“çš„ãªæƒ…å ±ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"
            ],
            "combined_question": f"{original_question} ã€è¿½åŠ æƒ…å ±ã€‘ {'; '.join(additional_info)}"
        }


# ========================
# å›ç­”ç”Ÿæˆï¼ˆè³ªå•ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ä»˜ã/ãªã—ï¼‰
# ========================

def generate_answer_directly(query: str, hybrid_retriever, law_type: str = "æ™¯è¡¨æ³•"):
    """è³ªå•ã®å…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥å›ç­”ã‚’ç”Ÿæˆï¼ˆè¿½åŠ æƒ…å ±çµ±åˆå¾Œç”¨ï¼‰"""
    
    print(f"  [ç›´æ¥å›ç­”ç”Ÿæˆ] è³ªå•: {query}")
    
    # 1. æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆæ³•å¾‹åã¨é©ç”¨é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ç²¾åº¦å‘ä¸Šï¼‰
    enhanced_query = f"{law_type} {query} é©ç”¨é™¤å¤–"
    
    # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆå¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    docs_and_scores = hybrid_retriever.search(enhanced_query, k=TOP_K_RESULTS * SEARCH_MULTIPLIER)
    
    # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆé¸æŠã•ã‚ŒãŸæ³•å¾‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰
    relevant_sources = LAW_SOURCE_MAPPING.get(law_type, [])
    if relevant_sources:
        filtered_docs = [
            (doc, score) for doc, score in docs_and_scores 
            if any(source in doc.metadata.get('source', '') for source in relevant_sources)
        ][:TOP_K_RESULTS]
    else:
        filtered_docs = docs_and_scores[:TOP_K_RESULTS]
    
    docs = [doc for doc, score in filtered_docs]
    
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model=GENERATION_MODEL,
        google_api_key=GOOGLE_API_KEY,
        temperature=ANSWER_GENERATION_TEMPERATURE,
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆï¼ˆutilsçµŒç”±ã§èª­ã¿è¾¼ã¿ï¼‰
    prompt = PromptTemplate.from_template(get_answer_generation_prompt())
    
    # RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    rag_chain = (
        {
            "context": lambda x: format_docs(docs),
            "question": lambda x: query,  # å…ƒã®ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # å›ç­”ã®ç”Ÿæˆ
    answer = rag_chain.invoke(query)
    
    # å‚ç…§å…ƒæƒ…å ±ã®æ•´å½¢ï¼ˆSlackç”¨ã€utilsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
    references = format_references(filtered_docs)
    
    return answer, references


def generate_answer(query: str, hybrid_retriever, law_type: str = "æ™¯è¡¨æ³•"):
    """è³ªå•ã«å¯¾ã—ã¦å›ç­”ã‚’ç”Ÿæˆï¼ˆæ³•å¾‹ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»æ‹¡å¼µï¼‰"""
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: è³ªå•ã®å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    print(f"  [è³ªå•ã®å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...] è³ªå•: {query}")
    clarity_result = check_question_clarity(query, law_type)
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: è³ªå•ãŒæ›–æ˜§ãªå ´åˆã¯è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°
    if not clarity_result.get("is_clear", True):
        print(f"  [åˆ¤å®š] è³ªå•ãŒæ›–æ˜§ - è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½")
        
        clarifying_questions = clarity_result.get("clarifying_questions", [])
        
        # è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆï¼ˆutilsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        clarification_message = create_clarification_message(
            clarifying_questions,
            law_type,
            max_questions=MAX_CLARIFYING_QUESTIONS
        )
        
        # è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°ã®å ´åˆã¯å‚ç…§ãªã—
        return clarification_message, []
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: è³ªå•ãŒå…·ä½“çš„ãªå ´åˆã¯å›ç­”ã‚’ç”Ÿæˆ
    print(f"  [åˆ¤å®š] è³ªå•ãŒå…·ä½“çš„ - å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™")
    
    # 1. æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆæ³•å¾‹åã¨é©ç”¨é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ç²¾åº¦å‘ä¸Šï¼‰
    enhanced_query = f"{law_type} {query} é©ç”¨é™¤å¤–"
    
    # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆå¤šã‚ã«å–å¾—ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    docs_and_scores = hybrid_retriever.search(enhanced_query, k=TOP_K_RESULTS * SEARCH_MULTIPLIER)
    
    # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆé¸æŠã•ã‚ŒãŸæ³•å¾‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰
    relevant_sources = LAW_SOURCE_MAPPING.get(law_type, [])
    if relevant_sources:
        filtered_docs = [
            (doc, score) for doc, score in docs_and_scores 
            if any(source in doc.metadata.get('source', '') for source in relevant_sources)
        ][:TOP_K_RESULTS]
    else:
        filtered_docs = docs_and_scores[:TOP_K_RESULTS]
    
    docs = [doc for doc, score in filtered_docs]
    
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model=GENERATION_MODEL,
        google_api_key=GOOGLE_API_KEY,
        temperature=ANSWER_GENERATION_TEMPERATURE,
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆï¼ˆutilsçµŒç”±ã§èª­ã¿è¾¼ã¿ï¼‰
    prompt = PromptTemplate.from_template(get_answer_generation_prompt())
    
    # RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    rag_chain = (
        {
            "context": lambda x: format_docs(docs),
            "question": lambda x: query,  # å…ƒã®ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨
            "law_type": lambda x: law_type
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # å›ç­”ã®ç”Ÿæˆ
    answer = rag_chain.invoke(query)
    
    # å‚ç…§å…ƒæƒ…å ±ã®æ•´å½¢ï¼ˆSlackç”¨ã€utilsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
    references = format_references(filtered_docs)
    
    return answer, references


# ========================
# Slack UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
# ========================

def create_law_selection_blocks(question: str):
    """æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ã‚’å«ã‚€Slack Blocksã‚’ä½œæˆ"""
    return [
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ã©ã®æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã‹ï¼Ÿ*\n\nè³ªå•: _{question}_"
            }
        },
        {
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ“œ æ™¯è¡¨æ³•"
                    },
                    "action_id": "select_law_keihyouhou",
                    "value": f"keihyouhou|||{question}"
                },
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ’° è³‡é‡‘æ±ºæ¸ˆæ³•"
                    },
                    "action_id": "select_law_shikin_kessai",
                    "value": f"shikin_kessai|||{question}"
                },
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ” å€‹äººæƒ…å ±ä¿è­·æ³•"
                    },
                    "action_id": "select_law_kojin_jouhou",
                    "value": f"kojin_jouhou|||{question}"
                },
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "ğŸ“ å°ç´™ç¨æ³•"
                    },
                    "action_id": "select_law_inshi_zei",
                    "value": f"inshi_zei|||{question}"
                }
            ]
        }
    ]


# ========================
# Slackã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
# ========================

@app.event("app_mention")
def handle_mention(event, say):
    """ãƒœãƒƒãƒˆãŒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ™‚ã®å‡¦ç†"""
    try:
        # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’é™¤å»ã—ã¦è³ªå•ã‚’æŠ½å‡º
        text = event['text']
        question = re.sub(r'<@[A-Z0-9]+>', '', text).strip()
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ç”¨ï¼‰
        thread_ts = event['ts']
        
        if not question:
            say("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹: @FAQ Bot æ™¯å“é¡ã®å®šç¾©ã‚’æ•™ãˆã¦ãã ã•ã„", thread_ts=thread_ts)
            return
        
        # æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        say(
            blocks=create_law_selection_blocks(question),
            text=f"ã©ã®æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã‹ï¼Ÿ\nè³ªå•: {question}",
            thread_ts=thread_ts
        )
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã‚‚ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        thread_ts = event.get('ts')
        say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", thread_ts=thread_ts)


@app.message("")
def handle_message(message, say, client):
    """DMã‚„é€šå¸¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¸ã®å¿œç­”ã€ãŠã‚ˆã³ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®è¿½åŠ æƒ…å ±ã®å‡¦ç†"""
    print(f"  [handle_messageå‘¼ã³å‡ºã—] message={message.get('text', '')[:50]}, channel_type={message.get('channel_type', 'N/A')}, bot_id={message.get('bot_id', 'N/A')}, thread_ts={message.get('thread_ts', 'N/A')}")
    
    # ãƒœãƒƒãƒˆã®æŠ•ç¨¿ã¯ç„¡è¦–
    if message.get('bot_id'):
        print(f"  [ã‚¹ã‚­ãƒƒãƒ—] ãƒœãƒƒãƒˆã®æŠ•ç¨¿")
        return
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ãƒã‚§ãƒƒã‚¯
    thread_ts = message.get('thread_ts')
    print(f"  [ãƒã‚§ãƒƒã‚¯] thread_ts={thread_ts}, contexts={list(thread_contexts.keys())}")
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯è¿½åŠ æƒ…å ±ã¨ã—ã¦å‡¦ç†
    if thread_ts and thread_ts in thread_contexts:
        try:
            context = thread_contexts[thread_ts]
            user_response = message['text'].strip()
            
            if not user_response:
                return
            
            print(f"  [ã‚¹ãƒ¬ãƒƒãƒ‰å†…å¿œç­”æ¤œçŸ¥] thread_ts={thread_ts}, response={user_response}")
            
            # è¿½åŠ æƒ…å ±ã‚’è¨˜éŒ²
            context['additional_info'].append(user_response)
            
            # ã€Œç¢ºèªä¸­ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
            say(f"ğŸ¤” è¿½åŠ æƒ…å ±ã‚’ç¢ºèªã—ã¦ã„ã¾ã™...\n> {user_response}", thread_ts=thread_ts)
            
            # è¿½åŠ æƒ…å ±ã‚’å«ã‚ã¦å†è©•ä¾¡
            recheck_result = recheck_question_with_additional_info(
                context['original_question'],
                context['additional_info'],
                context['law_type']
            )
            
            # ååˆ†ã«å…·ä½“çš„ã«ãªã£ãŸå ´åˆ
            if recheck_result.get('is_now_clear', False):
                combined_question = recheck_result.get('combined_question', context['original_question'])
                
                say(
                    f"âœ… **æƒ…å ±ãŒæƒã„ã¾ã—ãŸï¼å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™**\n\nçµ±åˆã•ã‚ŒãŸè³ªå•:\n> {combined_question}",
                    thread_ts=thread_ts
                )
                
                # çµ±åˆã•ã‚ŒãŸè³ªå•ã§å›ç­”ã‚’ç”Ÿæˆï¼ˆå…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥å›ç­”ï¼‰
                print(f"  [çµ±åˆè³ªå•ã§å›ç­”ç”Ÿæˆ] {combined_question}")
                law_type = context['law_type']
                answer, references = generate_answer_directly(combined_question, hybrid_retriever, law_type)
                
                # å›ç­”ã‚’é€ä¿¡ï¼ˆutilsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
                response_text = format_response_with_references(answer, references, law_type)
                say(response_text, thread_ts=thread_ts)
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
                del thread_contexts[thread_ts]
                print(f"  [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‰Šé™¤] thread_ts={thread_ts}")
                
            else:
                # ã¾ã ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯è¿½åŠ è³ªå•ï¼ˆutilsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
                still_missing = recheck_result.get('still_missing_aspects', [])
                next_questions = recheck_result.get('next_clarifying_questions', [])
                
                clarification_message = create_further_clarification_message(
                    next_questions,
                    still_missing,
                    max_questions=MAX_CLARIFYING_QUESTIONS
                )
                
                say(clarification_message, thread_ts=thread_ts)
            
            return
            
        except Exception as e:
            print(f"ã‚¹ãƒ¬ãƒƒãƒ‰å†…ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", thread_ts=thread_ts)
            return
    
    # ãƒãƒ£ãƒãƒ«ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
    channel_type = message.get('channel_type', '')
    
    # DMã®å ´åˆã®ã¿å¿œç­”
    if channel_type == 'im':
        try:
            question = message['text'].strip()
            
            if not question:
                return
            
            # æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ã‚’é€ä¿¡
            say(
                blocks=create_law_selection_blocks(question),
                text=f"ã©ã®æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã§ã™ã‹ï¼Ÿ\nè³ªå•: {question}"
            )
            
        except Exception as e:
            say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


# ãƒœã‚¿ãƒ³ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.action(re.compile("select_law_.*"))
def handle_law_selection(ack, body, say):
    """æ³•å¾‹é¸æŠãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸæ™‚ã®å‡¦ç†"""
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª
    ack()
    
    try:
        # ãƒœã‚¿ãƒ³ã®å€¤ã‹ã‚‰æ³•å¾‹ã‚¿ã‚¤ãƒ—ã¨è³ªå•ã‚’å–å¾—
        action_value = body['actions'][0]['value']
        law_key, question = action_value.split('|||', 1)
        law_type = LAW_TYPES.get(law_key, "æ™¯è¡¨æ³•")
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—
        thread_ts = body['message']['thread_ts'] if 'thread_ts' in body['message'] else body['message']['ts']
        
        # ã€Œè€ƒãˆä¸­ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        say(f"ğŸ¤” {law_type}ã«é–¢ã™ã‚‹è³ªå•ã¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆä¸­...\n> {question}", thread_ts=thread_ts)
        
        # å›ç­”ã‚’ç”Ÿæˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä»˜ãï¼‰
        answer, references = generate_answer(question, hybrid_retriever, law_type)
        
        # å›ç­”ãŒè¿½åŠ è³ªå•ï¼ˆå‚ç…§ãªã—ï¼‰ã®å ´åˆã€ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
        if not references:  # è¿½åŠ è³ªå•ã®å ´åˆ
            thread_contexts[thread_ts] = {
                "original_question": question,
                "law_type": law_type,
                "additional_info": [],
                "last_interaction": body.get('message', {}).get('ts')
            }
            print(f"  [ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜] thread_ts={thread_ts}, question={question}, law_type={law_type}")
        
        # å›ç­”ã‚’æ•´å½¢ï¼ˆSlackç”¨ã€utilsé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        if references:
            response_text = format_response_with_references(answer, references, law_type)
        else:
            # è¿½åŠ è³ªå•ã®å ´åˆã¯ãã®ã¾ã¾
            response_text = answer
        
        # å›ç­”ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ã«é€ä¿¡
        say(response_text, thread_ts=thread_ts)
        
    except Exception as e:
        thread_ts = body['message'].get('thread_ts') or body['message'].get('ts')
        say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", thread_ts=thread_ts)


if __name__ == "__main__":
    # ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    if not SLACK_BOT_TOKEN or not SLACK_APP_TOKEN:
        print("ã‚¨ãƒ©ãƒ¼: SLACK_BOT_TOKEN ã¨ SLACK_APP_TOKEN ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    if not OPENAI_API_KEY or not GOOGLE_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEY ã¨ GOOGLE_API_KEY ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    if not os.path.exists(CHROMA_DB_DIR):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ™ã‚¯ãƒˆãƒ«DB ({CHROMA_DB_DIR}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ã¾ãš prepare_database_openai.py ã‚’å®Ÿè¡Œã—ã¦ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã—ã¦ãã ã•ã„")
        exit(1)
    
    # ãƒ™ã‚¯ãƒˆãƒ«DBã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®åˆæœŸåŒ–
    print("FAQ Bot (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç‰ˆ) ã‚’èµ·å‹•ä¸­...")
    print(f"  - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ä¸Šä½{TOP_K_RESULTS}ä»¶ã‚’å–å¾—")
    print(f"  - æ³•å¾‹åˆ¥ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æœ‰åŠ¹")
    hybrid_retriever = load_vectordb_with_hybrid_search()
    
    print("\n" + "="*60)
    print("âœ“ FAQ Bot (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç‰ˆ) ãŒèµ·å‹•ã—ã¾ã—ãŸ")
    print("="*60)
    print("ãƒãƒ£ãƒãƒ«ã§ @FAQ Bot ã‚’ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã—ã¦è³ªå•ã—ã¦ãã ã•ã„")
    print("å¯¾å¿œæ³•å¾‹: æ™¯è¡¨æ³•ã€è³‡é‡‘æ±ºæ¸ˆæ³•ã€å€‹äººæƒ…å ±ä¿è­·æ³•ã€å°ç´™ç¨æ³•")
    print("BM25 + ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    print("\nçµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    print("="*60 + "\n")
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆDockerç”¨ï¼‰
    try:
        with open(HEALTH_CHECK_FILE, 'w') as f:
            f.write('ready')
    except Exception:
        pass  # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯/tmpãŒä½¿ãˆãªã„å ´åˆã‚‚ã‚ã‚‹ã®ã§ç„¡è¦–
    
    # Socket Modeã§èµ·å‹•
    handler = SocketModeHandler(app, SLACK_APP_TOKEN)
    handler.start()

