#!/usr/bin/env python3
"""
FAQ Bot for Slack with Hybrid Search
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸSlack Bot
"""

import os
import re
from dotenv import load_dotenv
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler

from langchain_openai import OpenAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

from hybrid_search import HybridSearchRetriever

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Slackè¨­å®š
SLACK_BOT_TOKEN = os.getenv("SLACK_BOT_TOKEN")
SLACK_APP_TOKEN = os.getenv("SLACK_APP_TOKEN")

# FAQ Botè¨­å®š
CHROMA_DB_DIR = "./chroma_db_openai"
TOP_K_RESULTS = 5  # æ¤œç´¢çµæœã®ä¸Šä½ä»¶æ•°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
PROMPT_TEMPLATE = """
ã‚ãªãŸã¯æ™¯å“è¡¨ç¤ºæ³•ã‚„FAQã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã™ã‚‹è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚

**é‡è¦ãªæŒ‡ç¤º**:
1. å›ç­”ã™ã‚‹éš›ã¯ã€å¿…ãšæƒ…å ±ã®å‡ºå…¸ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„
2. å„æ–‡ã‚„æ®µè½ã®æœ€å¾Œã«ã€ãã®æƒ…å ±ãŒã©ã®å‚ç…§ã‹ã‚‰æ¥ã¦ã„ã‚‹ã‹ã‚’ï¼ˆ[å‚ç…§1]ï¼‰ã®ã‚ˆã†ã«è¨˜è¼‰ã—ã¦ãã ã•ã„
3. è¤‡æ•°ã®å‚ç…§ã‹ã‚‰æƒ…å ±ã‚’å¾—ãŸå ´åˆã¯ã€ï¼ˆ[å‚ç…§1, 2]ï¼‰ã®ã‚ˆã†ã«è¨˜è¼‰ã—ã¦ãã ã•ã„
4. Slackç”¨ã«ã€ç®‡æ¡æ›¸ãã‚„æ®µè½ã‚’è¦‹ã‚„ã™ãæ•´å½¢ã—ã¦ãã ã•ã„
5. å…¨ãé–¢é€£ã™ã‚‹æƒ…å ±ãŒãªã„å ´åˆã¯ã€ã€Œæä¾›ã•ã‚ŒãŸæƒ…å ±ã«ã¯ã€ã“ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„
6. æ³•å¾‹æ¡æ–‡ã€æ–½è¡Œè¦å‰‡ã€FAQ ãã‚Œãã‚Œã®æƒ…å ±ã‚’åŒºåˆ¥ã—ã¦æ´»ç”¨ã—ã€åŒ…æ‹¬çš„ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
{context}

# è³ªå•
{question}

# å›ç­”ï¼ˆå¿…ãšå‚ç…§å…ƒã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ï¼‰
"""

# Slack Appã®åˆæœŸåŒ–
app = App(token=SLACK_BOT_TOKEN)


# ãƒ™ã‚¯ãƒˆãƒ«DBã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®åˆæœŸåŒ–
def load_vectordb_with_hybrid_search():
    """ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢retrieverã‚’ä½œæˆ"""
    embedding_model = OpenAIEmbeddings(
        model="text-embedding-3-large",
        openai_api_key=OPENAI_API_KEY
    )
    
    vectordb = Chroma(
        persist_directory=CHROMA_DB_DIR,
        embedding_function=embedding_model
    )
    
    hybrid_retriever = HybridSearchRetriever(
        vectordb=vectordb,
        alpha=0.5  # BM25ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’åŒã˜é‡ã¿ã§
    )
    
    return hybrid_retriever


def format_docs(docs):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦ã€å‚ç…§ç•ªå·ã‚’ä»˜ä¸"""
    context_parts = []
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get('source', 'ä¸æ˜')
        chunk_id = doc.metadata.get('chunk_id', 'ä¸æ˜')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çŸ­ç¸®
        if 'Q&A' in source:
            source_type = "FAQ"
        elif 'æ–½è¡Œè¦å‰‡' in source:
            source_type = "æ–½è¡Œè¦å‰‡"
        elif 'ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•.pdf' in source:
            source_type = "æ™¯è¡¨æ³•"
        else:
            source_type = source
        
        context_parts.append(
            f"[å‚ç…§{i}] (å‡ºå…¸: {source_type}, {source}, ID: {chunk_id})\n{doc.page_content}\n"
        )
    
    return "\n".join(context_parts)


def generate_answer(query: str, hybrid_retriever):
    """è³ªå•ã«å¯¾ã—ã¦å›ç­”ã‚’ç”Ÿæˆ"""
    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã§ä¸Šä½TOP_K_RESULTSä»¶ã‚’å–å¾—
    docs_and_scores = hybrid_retriever.search(query, k=TOP_K_RESULTS)
    docs = [doc for doc, score in docs_and_scores]
    
    # LLMã®åˆæœŸåŒ–
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.2,
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
    
    # RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
    rag_chain = (
        {
            "context": lambda x: format_docs(docs),
            "question": RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # å›ç­”ã®ç”Ÿæˆ
    answer = rag_chain.invoke(query)
    
    # å‚ç…§å…ƒæƒ…å ±ã®æ•´å½¢ï¼ˆSlackç”¨ï¼‰
    references = []
    for i, (doc, score) in enumerate(docs_and_scores, 1):
        source = doc.metadata.get('source', 'ä¸æ˜')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çŸ­ç¸®
        if 'Q&A' in source:
            source_label = "FAQ"
        elif 'æ–½è¡Œè¦å‰‡' in source:
            source_label = "æ–½è¡Œè¦å‰‡"
        elif 'ä¸å½“æ™¯å“é¡åŠã³ä¸å½“è¡¨ç¤ºé˜²æ­¢æ³•.pdf' in source:
            source_label = ":law: æ™¯è¡¨æ³•"
        else:
            source_label = source
        
        hybrid_score = doc.metadata.get('hybrid_score', 0)
        references.append(f"[{i}] {source_label} (ã‚¹ã‚³ã‚¢: {hybrid_score:.3f})")
    
    return answer, references


# Slackã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.event("app_mention")
def handle_mention(event, say):
    """ãƒœãƒƒãƒˆãŒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ™‚ã®å‡¦ç†"""
    try:
        # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’é™¤å»ã—ã¦è³ªå•ã‚’æŠ½å‡º
        text = event['text']
        question = re.sub(r'<@[A-Z0-9]+>', '', text).strip()
        
        if not question:
            say("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹: @FAQ Bot æ™¯å“é¡ã®å®šç¾©ã‚’æ•™ãˆã¦ãã ã•ã„")
            return
        
        # ã€Œè€ƒãˆä¸­ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        say(f"ğŸ¤” è³ªå•ã‚’ç¢ºèªã—ã¦ã„ã¾ã™...\n> {question}")
        
        # å›ç­”ã‚’ç”Ÿæˆ
        answer, references = generate_answer(question, hybrid_retriever)
        
        # å›ç­”ã‚’æ•´å½¢ï¼ˆSlackç”¨ï¼‰
        response_text = f"*ğŸ“ å›ç­”:*\n{answer}\n\n*ğŸ“š å‚ç…§å…ƒ (æ³•å¾‹ãƒ»æ–½è¡Œè¦å‰‡ãƒ»FAQ):*\n"
        for ref in references:
            response_text += f"  â€¢ {ref}\n"
        
        # å›ç­”ã‚’é€ä¿¡
        say(response_text)
        
    except Exception as e:
        say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


@app.message("")
def handle_message(message, say):
    """DMã‚„é€šå¸¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¸ã®å¿œç­”"""
    # ãƒœãƒƒãƒˆã®æŠ•ç¨¿ã¯ç„¡è¦–
    if message.get('bot_id'):
        return
    
    # ãƒãƒ£ãƒãƒ«ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
    channel_type = message.get('channel_type', '')
    
    # DMã®å ´åˆã®ã¿å¿œç­”
    if channel_type == 'im':
        try:
            question = message['text'].strip()
            
            if not question:
                return
            
            # ã€Œè€ƒãˆä¸­ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
            say(f"ğŸ¤” è³ªå•ã‚’ç¢ºèªã—ã¦ã„ã¾ã™...\n> {question}")
            
            # å›ç­”ã‚’ç”Ÿæˆ
            answer, references = generate_answer(question, hybrid_retriever)
            
            # å›ç­”ã‚’æ•´å½¢
            response_text = f"*ğŸ“ å›ç­”:*\n{answer}\n\n*ğŸ“š å‚ç…§å…ƒ:*\n"
            for ref in references:
                response_text += f"  â€¢ {ref}\n"
            
            # å›ç­”ã‚’é€ä¿¡
            say(response_text)
            
        except Exception as e:
            say(f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


if __name__ == "__main__":
    # ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    if not SLACK_BOT_TOKEN or not SLACK_APP_TOKEN:
        print("ã‚¨ãƒ©ãƒ¼: SLACK_BOT_TOKEN ã¨ SLACK_APP_TOKEN ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    if not OPENAI_API_KEY or not GOOGLE_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEY ã¨ GOOGLE_API_KEY ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)
    
    if not os.path.exists(CHROMA_DB_DIR):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ™ã‚¯ãƒˆãƒ«DB ({CHROMA_DB_DIR}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ã¾ãš prepare_database_openai.py ã‚’å®Ÿè¡Œã—ã¦ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã—ã¦ãã ã•ã„")
        exit(1)
    
    # ãƒ™ã‚¯ãƒˆãƒ«DBã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®åˆæœŸåŒ–
    print("FAQ Bot (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç‰ˆ) ã‚’èµ·å‹•ä¸­...")
    print(f"  - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ä¸Šä½{TOP_K_RESULTS}ä»¶ã‚’å–å¾—")
    hybrid_retriever = load_vectordb_with_hybrid_search()
    
    print("\n" + "="*60)
    print("âœ“ FAQ Bot (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç‰ˆ) ãŒèµ·å‹•ã—ã¾ã—ãŸ")
    print("="*60)
    print("ãƒãƒ£ãƒãƒ«ã§ @FAQ Bot ã‚’ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã—ã¦è³ªå•ã—ã¦ãã ã•ã„")
    print("BM25 + ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§æœ€é©ãªæƒ…å ±ã‚’å–å¾—ã—ã¾ã™")
    print("\nçµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    print("="*60 + "\n")
    
    # Socket Modeã§èµ·å‹•
    handler = SocketModeHandler(app, SLACK_APP_TOKEN)
    handler.start()

